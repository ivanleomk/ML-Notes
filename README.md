These are my existing ML notes which are a record of all the things I've learnt. Figured this would help me to get more experience working with RAG systems.

[Elicit Machine Learning Guide](Elicit%20Machine%20Learning%20Guide.md): My current progress on the Elicit Machine Learning Reading List

# Resources

[A Guide To Hyperparameters](/A%20Guide%20To%20Hyperparameters.md) : These are some notes that I took about training hyper-parameters when fine-tuning models

[Large Language Models](/Large%20Language%20Models.md) : A quick introduction to what is a Large Language Model

[Recommendation Systems](/Recommendation%20Systems.md) : A quick dive into what a recommendation system is

[Pytorch](Pytorch.md) : A guide to using auto differentiation libraries in Machine Learning

## Papers

[Matryoshka Embeddings](/Matryoshka%20Embeddings.md): Training embedding models that are able to work at a variety of different embedding dimensions

[Language Models Are Unsupervised Multitask Learners](/Language%20Models%20Are%20Unsupervised%20Multitask%20Learners.md) : How GPT-2 challenged a traditional paradigm of pre-train -> fine-tune on task with its auto-regressive prompting ability

[A Comprehensive Overview of Large Language Models](/A%20Comprehensive%20Overview%20of%20Large%20Language%20Models.md) : A walkthrough of the key ideas and concepts around large language models

[Improving Language Understanding by Generative Pre-Training](/Improving%20Language%20Understanding%20by%20Generative%20Pre-Training.md) : How GPT-1 helped to bring forth a huge revolution in the NLP space by showing efficient transfer learning abilities
