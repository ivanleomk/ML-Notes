These are my existing ML notes which are a record of all the things I've learnt. Figured this would help me to get more experience working with RAG systems. 

# Resources

[[A Guide To Hyperparameters]] : These are some notes that I took about training hyper-parameters when fine-tuning models

[[Large Language Models]] : A quick introduction to what is a Large Language Model

[[Recommendation Systems]] : A quick dive into what a recommendation system is

[[Machine Learning]] : What is this all about?

[[Pytorch]] : A brief introduction to pytorch

## Papers

[[Matryoshka Embeddings]]: Training embedding models that are able to work at a variety of different embedding dimensions

[[Language Models Are Unsupervised Multitask Learners]] : How GPT-2 challenged a traditional paradigm of pre-train -> fine-tune on task with its auto-regressive prompting ability

[[A Comprehensive Overview of Large Language Models]] : A walkthrough of the key ideas and concepts around large language models

[[Improving Language Understanding by Generative Pre-Training]] : How GPT-1 helped to bring forth a huge revolution in the NLP space by showing efficient transfer learning abilities